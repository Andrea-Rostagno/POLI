{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97f37450-bc3f-4f0c-ac49-340871c79fe9",
   "metadata": {},
   "source": [
    "# Python Homework: PCA ed Eigenfaces\n",
    "## Francesco Della Santa, Matematica per l'Intelligenza Artificiale, Politecnico di Torino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "confused-tribute",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***** NOTA BENE! *****\n",
    "# perché %matplotlib widget funzioni, installare nell'ambiente virtuale \n",
    "# il pacchetto ipympl con il comando:\n",
    "# pip install ipympl\n",
    "#\n",
    "# ATTENZIONE: perché funzioni è necessario chiudere e rilanciare jupyter-lab\n",
    "#\n",
    "# STILE DI VISUALIZZAZIONE PLOT FATTI CON MATPLOTLIB\n",
    "%matplotlib widget\n",
    "#\n",
    "#\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "colonial-albany",
   "metadata": {},
   "source": [
    "# Importazione del Dataset “Labeled Faces in the Wild”\n",
    "\n",
    "Il dataset in questione è disponibile tramite il sottomodulo \"datasets\" di scikit-learn (come il dataset iris, wine e molti altri) e la funzione fetch_lfw_people. Documentazione completa della funzione qui: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_lfw_people.html#sklearn.datasets.fetch_lfw_people\n",
    "\n",
    "Il dataset caricato dalla funzione restituisce (ormai vecchie) immagini di volti famosi.\n",
    "L'oggetto restituito è della classe \"Bunch\" di scikit-learn, dal funzionamento simile ai dizionari (per come lo utilizzeremo, potrebbe essere di fatto un dizionario)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "synthetic-twenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Il codice presente in questa cella serve nel caso si verifichi un errore del tipo\n",
    "#\n",
    "# \"URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1124)>\"\n",
    "#\n",
    "# al momento di chiamare la funzione fetch_lfw_people di sklearn.datasets\n",
    "#\n",
    "# ATTENZIONE: il codice di questa cella non è quindi sempre necessario; se quindi non lo fosse, commentarlo pure.\n",
    "#\n",
    "\n",
    "import os, ssl\n",
    "\n",
    "if (not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None)):\n",
    "    ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cross-sunset",
   "metadata": {},
   "source": [
    "## Importazione di parte del dataset e prime ispezioni del contenuto\n",
    "\n",
    "Di seguito importiamo parte del dataset, stampiamo la descrizione ufficiale fornita da scikit-learn ed esploriamo un po' il contenuto.\n",
    "\n",
    "### Importazione e Stampa Descrizione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "continuous-turkey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[0.9973857 , 0.99607843, 0.9921568 , ..., 0.38169935, 0.38823533,\n",
       "         0.3803922 ],\n",
       "        [0.14771242, 0.19738562, 0.1751634 , ..., 0.45751634, 0.44444445,\n",
       "         0.53594774],\n",
       "        [0.34379086, 0.39477125, 0.49150327, ..., 0.709804  , 0.72156864,\n",
       "         0.7163399 ],\n",
       "        ...,\n",
       "        [0.3633987 , 0.3372549 , 0.30718955, ..., 0.19738562, 0.22091503,\n",
       "         0.19346406],\n",
       "        [0.19346406, 0.24705882, 0.34248367, ..., 0.7346406 , 0.6640523 ,\n",
       "         0.6117647 ],\n",
       "        [0.11633987, 0.10196079, 0.1267974 , ..., 0.13333334, 0.13725491,\n",
       "         0.2535948 ]], dtype=float32),\n",
       " 'images': array([[[0.9973857 , 0.99607843, 0.9921568 , ..., 0.29803923,\n",
       "          0.24836601, 0.20653595],\n",
       "         [0.9973857 , 0.9921569 , 0.9908497 , ..., 0.30588236,\n",
       "          0.2535948 , 0.21568628],\n",
       "         [0.96078426, 0.93071896, 0.8679738 , ..., 0.2875817 ,\n",
       "          0.24183007, 0.21568628],\n",
       "         ...,\n",
       "         [0.34509805, 0.26143792, 0.17385621, ..., 0.4248366 ,\n",
       "          0.40261438, 0.39084968],\n",
       "         [0.30980393, 0.23398693, 0.17124183, ..., 0.39869282,\n",
       "          0.4013072 , 0.3764706 ],\n",
       "         [0.28366014, 0.2248366 , 0.18039216, ..., 0.38169935,\n",
       "          0.38823533, 0.3803922 ]],\n",
       " \n",
       "        [[0.14771242, 0.19738562, 0.1751634 , ..., 0.24183007,\n",
       "          0.2       , 0.14509805],\n",
       "         [0.18039216, 0.24836601, 0.24575163, ..., 0.21437909,\n",
       "          0.21960784, 0.1751634 ],\n",
       "         [0.21045752, 0.303268  , 0.33594772, ..., 0.2653595 ,\n",
       "          0.18431373, 0.16993465],\n",
       "         ...,\n",
       "         [0.2875817 , 0.29803923, 0.29673204, ..., 0.503268  ,\n",
       "          0.46797386, 0.4535948 ],\n",
       "         [0.29411766, 0.29803923, 0.303268  , ..., 0.4928105 ,\n",
       "          0.4496732 , 0.45359477],\n",
       "         [0.30457518, 0.29673204, 0.29673204, ..., 0.45751634,\n",
       "          0.44444445, 0.53594774]],\n",
       " \n",
       "        [[0.34379086, 0.39477125, 0.49150327, ..., 0.5803922 ,\n",
       "          0.58954257, 0.58300656],\n",
       "         [0.38169935, 0.5071896 , 0.57124186, ..., 0.6261439 ,\n",
       "          0.5908497 , 0.5751634 ],\n",
       "         [0.48366013, 0.5686275 , 0.579085  , ..., 0.64183015,\n",
       "          0.59738564, 0.5751634 ],\n",
       "         ...,\n",
       "         [0.29673204, 0.2875817 , 0.28496733, ..., 0.46013072,\n",
       "          0.6732027 , 0.70326805],\n",
       "         [0.28627452, 0.26666668, 0.27058825, ..., 0.5908497 ,\n",
       "          0.7267974 , 0.7098039 ],\n",
       "         [0.3150327 , 0.25490198, 0.26013073, ..., 0.709804  ,\n",
       "          0.72156864, 0.7163399 ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0.3633987 , 0.3372549 , 0.30718955, ..., 0.1633987 ,\n",
       "          0.1633987 , 0.18562092],\n",
       "         [0.35947713, 0.3124183 , 0.32026145, ..., 0.16993465,\n",
       "          0.16209151, 0.17124183],\n",
       "         [0.30457518, 0.26666668, 0.38039216, ..., 0.18562092,\n",
       "          0.17254902, 0.16993465],\n",
       "         ...,\n",
       "         [0.38169935, 0.36601308, 0.35947713, ..., 0.2901961 ,\n",
       "          0.34509805, 0.4       ],\n",
       "         [0.36078432, 0.35816994, 0.37254903, ..., 0.20261438,\n",
       "          0.25490198, 0.27450982],\n",
       "         [0.32156864, 0.3281046 , 0.34117648, ..., 0.19738562,\n",
       "          0.22091503, 0.19346406]],\n",
       " \n",
       "        [[0.19346406, 0.24705882, 0.34248367, ..., 0.5882353 ,\n",
       "          0.5947712 , 0.5647059 ],\n",
       "         [0.22875817, 0.32287583, 0.39084968, ..., 0.58300656,\n",
       "          0.56078434, 0.55947715],\n",
       "         [0.23006536, 0.351634  , 0.37124184, ..., 0.5882353 ,\n",
       "          0.53464055, 0.53464055],\n",
       "         ...,\n",
       "         [0.23660131, 0.23921569, 0.24313726, ..., 0.5542484 ,\n",
       "          0.63137263, 0.6104575 ],\n",
       "         [0.24052288, 0.24183007, 0.24575163, ..., 0.71111107,\n",
       "          0.6535948 , 0.6169935 ],\n",
       "         [0.24183007, 0.24052288, 0.24444444, ..., 0.7346406 ,\n",
       "          0.6640523 , 0.6117647 ]],\n",
       " \n",
       "        [[0.11633987, 0.10196079, 0.1267974 , ..., 0.34248367,\n",
       "          0.20130719, 0.17908497],\n",
       "         [0.12156863, 0.12418301, 0.14379086, ..., 0.41045752,\n",
       "          0.20522876, 0.15816994],\n",
       "         [0.13071896, 0.13202615, 0.14901961, ..., 0.4888889 ,\n",
       "          0.26928106, 0.19477125],\n",
       "         ...,\n",
       "         [0.18169935, 0.17254902, 0.17254902, ..., 0.09281046,\n",
       "          0.07058824, 0.13986929],\n",
       "         [0.16470589, 0.1633987 , 0.1764706 , ..., 0.0875817 ,\n",
       "          0.10326798, 0.1764706 ],\n",
       "         [0.17908497, 0.19477125, 0.20392157, ..., 0.13333334,\n",
       "          0.13725491, 0.2535948 ]]], dtype=float32),\n",
       " 'target': array([5, 6, 3, ..., 5, 3, 5], dtype=int64),\n",
       " 'target_names': array(['Ariel Sharon', 'Colin Powell', 'Donald Rumsfeld', 'George W Bush',\n",
       "        'Gerhard Schroeder', 'Hugo Chavez', 'Tony Blair'], dtype='<U17'),\n",
       " 'DESCR': \".. _labeled_faces_in_the_wild_dataset:\\n\\nThe Labeled Faces in the Wild face recognition dataset\\n------------------------------------------------------\\n\\nThis dataset is a collection of JPEG pictures of famous people collected\\nover the internet, all details are available on the official website:\\n\\nhttp://vis-www.cs.umass.edu/lfw/\\n\\nEach picture is centered on a single face. The typical task is called\\nFace Verification: given a pair of two pictures, a binary classifier\\nmust predict whether the two images are from the same person.\\n\\nAn alternative task, Face Recognition or Face Identification is:\\ngiven the picture of the face of an unknown person, identify the name\\nof the person by referring to a gallery of previously seen pictures of\\nidentified persons.\\n\\nBoth Face Verification and Face Recognition are tasks that are typically\\nperformed on the output of a model trained to perform Face Detection. The\\nmost popular model for Face Detection is called Viola-Jones and is\\nimplemented in the OpenCV library. The LFW faces were extracted by this\\nface detector from various online websites.\\n\\n**Data Set Characteristics:**\\n\\n=================   =======================\\nClasses                                5749\\nSamples total                         13233\\nDimensionality                         5828\\nFeatures            real, between 0 and 255\\n=================   =======================\\n\\n|details-start|\\n**Usage**\\n|details-split|\\n\\n``scikit-learn`` provides two loaders that will automatically download,\\ncache, parse the metadata files, decode the jpeg and convert the\\ninteresting slices into memmapped numpy arrays. This dataset size is more\\nthan 200 MB. The first load typically takes more than a couple of minutes\\nto fully decode the relevant part of the JPEG files into numpy arrays. If\\nthe dataset has  been loaded once, the following times the loading times\\nless than 200ms by using a memmapped version memoized on the disk in the\\n``~/scikit_learn_data/lfw_home/`` folder using ``joblib``.\\n\\nThe first loader is used for the Face Identification task: a multi-class\\nclassification task (hence supervised learning)::\\n\\n  >>> from sklearn.datasets import fetch_lfw_people\\n  >>> lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\\n\\n  >>> for name in lfw_people.target_names:\\n  ...     print(name)\\n  ...\\n  Ariel Sharon\\n  Colin Powell\\n  Donald Rumsfeld\\n  George W Bush\\n  Gerhard Schroeder\\n  Hugo Chavez\\n  Tony Blair\\n\\nThe default slice is a rectangular shape around the face, removing\\nmost of the background::\\n\\n  >>> lfw_people.data.dtype\\n  dtype('float32')\\n\\n  >>> lfw_people.data.shape\\n  (1288, 1850)\\n\\n  >>> lfw_people.images.shape\\n  (1288, 50, 37)\\n\\nEach of the ``1140`` faces is assigned to a single person id in the ``target``\\narray::\\n\\n  >>> lfw_people.target.shape\\n  (1288,)\\n\\n  >>> list(lfw_people.target[:10])\\n  [5, 6, 3, 1, 0, 1, 3, 4, 3, 0]\\n\\nThe second loader is typically used for the face verification task: each sample\\nis a pair of two picture belonging or not to the same person::\\n\\n  >>> from sklearn.datasets import fetch_lfw_pairs\\n  >>> lfw_pairs_train = fetch_lfw_pairs(subset='train')\\n\\n  >>> list(lfw_pairs_train.target_names)\\n  ['Different persons', 'Same person']\\n\\n  >>> lfw_pairs_train.pairs.shape\\n  (2200, 2, 62, 47)\\n\\n  >>> lfw_pairs_train.data.shape\\n  (2200, 5828)\\n\\n  >>> lfw_pairs_train.target.shape\\n  (2200,)\\n\\nBoth for the :func:`sklearn.datasets.fetch_lfw_people` and\\n:func:`sklearn.datasets.fetch_lfw_pairs` function it is\\npossible to get an additional dimension with the RGB color channels by\\npassing ``color=True``, in that case the shape will be\\n``(2200, 2, 62, 47, 3)``.\\n\\nThe :func:`sklearn.datasets.fetch_lfw_pairs` datasets is subdivided into\\n3 subsets: the development ``train`` set, the development ``test`` set and\\nan evaluation ``10_folds`` set meant to compute performance metrics using a\\n10-folds cross validation scheme.\\n\\n|details-end|\\n\\n.. topic:: References:\\n\\n * `Labeled Faces in the Wild: A Database for Studying Face Recognition\\n   in Unconstrained Environments.\\n   <http://vis-www.cs.umass.edu/lfw/lfw.pdf>`_\\n   Gary B. Huang, Manu Ramesh, Tamara Berg, and Erik Learned-Miller.\\n   University of Massachusetts, Amherst, Technical Report 07-49, October, 2007.\\n\\n\\n.. topic:: Examples:\\n\\n   * :ref:`sphx_glr_auto_examples_applications_plot_face_recognition.py`\\n\"}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _labeled_faces_in_the_wild_dataset:\n",
      "\n",
      "The Labeled Faces in the Wild face recognition dataset\n",
      "------------------------------------------------------\n",
      "\n",
      "This dataset is a collection of JPEG pictures of famous people collected\n",
      "over the internet, all details are available on the official website:\n",
      "\n",
      "http://vis-www.cs.umass.edu/lfw/\n",
      "\n",
      "Each picture is centered on a single face. The typical task is called\n",
      "Face Verification: given a pair of two pictures, a binary classifier\n",
      "must predict whether the two images are from the same person.\n",
      "\n",
      "An alternative task, Face Recognition or Face Identification is:\n",
      "given the picture of the face of an unknown person, identify the name\n",
      "of the person by referring to a gallery of previously seen pictures of\n",
      "identified persons.\n",
      "\n",
      "Both Face Verification and Face Recognition are tasks that are typically\n",
      "performed on the output of a model trained to perform Face Detection. The\n",
      "most popular model for Face Detection is called Viola-Jones and is\n",
      "implemented in the OpenCV library. The LFW faces were extracted by this\n",
      "face detector from various online websites.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "=================   =======================\n",
      "Classes                                5749\n",
      "Samples total                         13233\n",
      "Dimensionality                         5828\n",
      "Features            real, between 0 and 255\n",
      "=================   =======================\n",
      "\n",
      "|details-start|\n",
      "**Usage**\n",
      "|details-split|\n",
      "\n",
      "``scikit-learn`` provides two loaders that will automatically download,\n",
      "cache, parse the metadata files, decode the jpeg and convert the\n",
      "interesting slices into memmapped numpy arrays. This dataset size is more\n",
      "than 200 MB. The first load typically takes more than a couple of minutes\n",
      "to fully decode the relevant part of the JPEG files into numpy arrays. If\n",
      "the dataset has  been loaded once, the following times the loading times\n",
      "less than 200ms by using a memmapped version memoized on the disk in the\n",
      "``~/scikit_learn_data/lfw_home/`` folder using ``joblib``.\n",
      "\n",
      "The first loader is used for the Face Identification task: a multi-class\n",
      "classification task (hence supervised learning)::\n",
      "\n",
      "  >>> from sklearn.datasets import fetch_lfw_people\n",
      "  >>> lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
      "\n",
      "  >>> for name in lfw_people.target_names:\n",
      "  ...     print(name)\n",
      "  ...\n",
      "  Ariel Sharon\n",
      "  Colin Powell\n",
      "  Donald Rumsfeld\n",
      "  George W Bush\n",
      "  Gerhard Schroeder\n",
      "  Hugo Chavez\n",
      "  Tony Blair\n",
      "\n",
      "The default slice is a rectangular shape around the face, removing\n",
      "most of the background::\n",
      "\n",
      "  >>> lfw_people.data.dtype\n",
      "  dtype('float32')\n",
      "\n",
      "  >>> lfw_people.data.shape\n",
      "  (1288, 1850)\n",
      "\n",
      "  >>> lfw_people.images.shape\n",
      "  (1288, 50, 37)\n",
      "\n",
      "Each of the ``1140`` faces is assigned to a single person id in the ``target``\n",
      "array::\n",
      "\n",
      "  >>> lfw_people.target.shape\n",
      "  (1288,)\n",
      "\n",
      "  >>> list(lfw_people.target[:10])\n",
      "  [5, 6, 3, 1, 0, 1, 3, 4, 3, 0]\n",
      "\n",
      "The second loader is typically used for the face verification task: each sample\n",
      "is a pair of two picture belonging or not to the same person::\n",
      "\n",
      "  >>> from sklearn.datasets import fetch_lfw_pairs\n",
      "  >>> lfw_pairs_train = fetch_lfw_pairs(subset='train')\n",
      "\n",
      "  >>> list(lfw_pairs_train.target_names)\n",
      "  ['Different persons', 'Same person']\n",
      "\n",
      "  >>> lfw_pairs_train.pairs.shape\n",
      "  (2200, 2, 62, 47)\n",
      "\n",
      "  >>> lfw_pairs_train.data.shape\n",
      "  (2200, 5828)\n",
      "\n",
      "  >>> lfw_pairs_train.target.shape\n",
      "  (2200,)\n",
      "\n",
      "Both for the :func:`sklearn.datasets.fetch_lfw_people` and\n",
      ":func:`sklearn.datasets.fetch_lfw_pairs` function it is\n",
      "possible to get an additional dimension with the RGB color channels by\n",
      "passing ``color=True``, in that case the shape will be\n",
      "``(2200, 2, 62, 47, 3)``.\n",
      "\n",
      "The :func:`sklearn.datasets.fetch_lfw_pairs` datasets is subdivided into\n",
      "3 subsets: the development ``train`` set, the development ``test`` set and\n",
      "an evaluation ``10_folds`` set meant to compute performance metrics using a\n",
      "10-folds cross validation scheme.\n",
      "\n",
      "|details-end|\n",
      "\n",
      ".. topic:: References:\n",
      "\n",
      " * `Labeled Faces in the Wild: A Database for Studying Face Recognition\n",
      "   in Unconstrained Environments.\n",
      "   <http://vis-www.cs.umass.edu/lfw/lfw.pdf>`_\n",
      "   Gary B. Huang, Manu Ramesh, Tamara Berg, and Erik Learned-Miller.\n",
      "   University of Massachusetts, Amherst, Technical Report 07-49, October, 2007.\n",
      "\n",
      "\n",
      ".. topic:: Examples:\n",
      "\n",
      "   * :ref:`sphx_glr_auto_examples_applications_plot_face_recognition.py`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lfw_people = datasets.fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
    "#display(lfw_people)\n",
    "print(lfw_people['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "leading-enzyme",
   "metadata": {},
   "source": [
    "### Visualizzazioni \"Esplorative\"\n",
    "\n",
    "Prima di tutto, per comodità, salviamo in variabili apposite i dati contenuti nel simil-dizionario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "regulation-driver",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_data = lfw_people['data']\n",
    "face_images = lfw_people['images']\n",
    "face_tnames = lfw_people['target_names']\n",
    "face_targets = lfw_people['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "criminal-responsibility",
   "metadata": {},
   "source": [
    "\n",
    "Per praticità, creiamoci dei DataFrame di lavoro\n",
    "\n",
    "**ESERCIZIO:** Completare il codice della cella seguente per creare il DataFrame \"face_targets_df\" avente per colonne \"target\", con i valori di \"face_targets\", e \"target_names\", avente come valori le stringhe di nomi in \"face_tnames\" corrispondenti ai valori nella colonna accanto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "instant-fight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DataFrame delle immagini rappresentate come vettori\n",
    "face_data_df = pd.DataFrame(face_data)\n",
    "\n",
    "\n",
    "# DataFrame delle classi di appartenenza e dei nomi\n",
    "face_targets_df = pd.DataFrame(columns=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "unsigned-frank",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1840</th>\n",
       "      <th>1841</th>\n",
       "      <th>1842</th>\n",
       "      <th>1843</th>\n",
       "      <th>1844</th>\n",
       "      <th>1845</th>\n",
       "      <th>1846</th>\n",
       "      <th>1847</th>\n",
       "      <th>1848</th>\n",
       "      <th>1849</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.997386</td>\n",
       "      <td>0.996078</td>\n",
       "      <td>0.992157</td>\n",
       "      <td>0.966013</td>\n",
       "      <td>0.758170</td>\n",
       "      <td>0.569935</td>\n",
       "      <td>0.700654</td>\n",
       "      <td>0.794771</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>0.767320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.437909</td>\n",
       "      <td>0.426144</td>\n",
       "      <td>0.422222</td>\n",
       "      <td>0.415686</td>\n",
       "      <td>0.401307</td>\n",
       "      <td>0.393464</td>\n",
       "      <td>0.390850</td>\n",
       "      <td>0.381699</td>\n",
       "      <td>0.388235</td>\n",
       "      <td>0.380392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.147712</td>\n",
       "      <td>0.197386</td>\n",
       "      <td>0.175163</td>\n",
       "      <td>0.192157</td>\n",
       "      <td>0.385621</td>\n",
       "      <td>0.473203</td>\n",
       "      <td>0.543791</td>\n",
       "      <td>0.615686</td>\n",
       "      <td>0.671895</td>\n",
       "      <td>0.694118</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168627</td>\n",
       "      <td>0.239216</td>\n",
       "      <td>0.296732</td>\n",
       "      <td>0.307190</td>\n",
       "      <td>0.325490</td>\n",
       "      <td>0.410458</td>\n",
       "      <td>0.487582</td>\n",
       "      <td>0.457516</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.535948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.343791</td>\n",
       "      <td>0.394771</td>\n",
       "      <td>0.491503</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.597386</td>\n",
       "      <td>0.611765</td>\n",
       "      <td>0.606536</td>\n",
       "      <td>0.626144</td>\n",
       "      <td>0.640523</td>\n",
       "      <td>0.652288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.483660</td>\n",
       "      <td>0.430065</td>\n",
       "      <td>0.379085</td>\n",
       "      <td>0.410458</td>\n",
       "      <td>0.498039</td>\n",
       "      <td>0.448366</td>\n",
       "      <td>0.481046</td>\n",
       "      <td>0.709804</td>\n",
       "      <td>0.721569</td>\n",
       "      <td>0.716340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.047059</td>\n",
       "      <td>0.016993</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.016993</td>\n",
       "      <td>0.031373</td>\n",
       "      <td>0.230065</td>\n",
       "      <td>0.677124</td>\n",
       "      <td>0.667974</td>\n",
       "      <td>0.641830</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.481046</td>\n",
       "      <td>0.749020</td>\n",
       "      <td>0.903268</td>\n",
       "      <td>0.915033</td>\n",
       "      <td>0.918954</td>\n",
       "      <td>0.925490</td>\n",
       "      <td>0.513725</td>\n",
       "      <td>0.065359</td>\n",
       "      <td>0.142484</td>\n",
       "      <td>0.201307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.471895</td>\n",
       "      <td>0.458824</td>\n",
       "      <td>0.486275</td>\n",
       "      <td>0.499346</td>\n",
       "      <td>0.494118</td>\n",
       "      <td>0.513726</td>\n",
       "      <td>0.545098</td>\n",
       "      <td>0.543791</td>\n",
       "      <td>0.560784</td>\n",
       "      <td>0.581699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.107190</td>\n",
       "      <td>0.062745</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.018301</td>\n",
       "      <td>0.018301</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.036601</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.250980</td>\n",
       "      <td>0.278431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1850 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6     \\\n",
       "0  0.997386  0.996078  0.992157  0.966013  0.758170  0.569935  0.700654   \n",
       "1  0.147712  0.197386  0.175163  0.192157  0.385621  0.473203  0.543791   \n",
       "2  0.343791  0.394771  0.491503  0.555556  0.597386  0.611765  0.606536   \n",
       "3  0.047059  0.016993  0.023529  0.016993  0.031373  0.230065  0.677124   \n",
       "4  0.471895  0.458824  0.486275  0.499346  0.494118  0.513726  0.545098   \n",
       "\n",
       "       7         8         9     ...      1840      1841      1842      1843  \\\n",
       "0  0.794771  0.784314  0.767320  ...  0.437909  0.426144  0.422222  0.415686   \n",
       "1  0.615686  0.671895  0.694118  ...  0.168627  0.239216  0.296732  0.307190   \n",
       "2  0.626144  0.640523  0.652288  ...  0.483660  0.430065  0.379085  0.410458   \n",
       "3  0.667974  0.641830  0.400000  ...  0.481046  0.749020  0.903268  0.915033   \n",
       "4  0.543791  0.560784  0.581699  ...  0.107190  0.062745  0.019608  0.018301   \n",
       "\n",
       "       1844      1845      1846      1847      1848      1849  \n",
       "0  0.401307  0.393464  0.390850  0.381699  0.388235  0.380392  \n",
       "1  0.325490  0.410458  0.487582  0.457516  0.444444  0.535948  \n",
       "2  0.498039  0.448366  0.481046  0.709804  0.721569  0.716340  \n",
       "3  0.918954  0.925490  0.513725  0.065359  0.142484  0.201307  \n",
       "4  0.018301  0.039216  0.036601  0.078431  0.250980  0.278431  \n",
       "\n",
       "[5 rows x 1850 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "postal-garbage",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ellipsis' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mface_targets_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ellipsis' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "face_targets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plastic-hampshire",
   "metadata": {},
   "source": [
    " \n",
    " \n",
    " Vediamo la distribuzione dei volti all'interno del dataset.\n",
    " \n",
    " **ESERCIZIO:** Completare il codice nella cella seguente per visualizzare la distribuzione dei volti nel dataset.\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "better-upset",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Definire face_counts sfruttando il metodo \"value_counts\" delle Serie rispetto alla \n",
    "# colonna 'target_names' di face_targets_df\n",
    "face_counts = ...\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(..., ...)\n",
    "plt.xticks(ticks=np.arange(len(face_counts.values)), \n",
    "           labels=face_counts.index.to_list(),\n",
    "           rotation=15)\n",
    "plt.title('DISTRIBUZIONE VOLTI')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerous-location",
   "metadata": {},
   "source": [
    "Visualizziamo alcuni dei volti, sia come immagine che come vettore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "united-question",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raccogliamo gli indici corrispondenti alle varie classi in un dizionario\n",
    "\n",
    "class_indices = {}\n",
    "\n",
    "for name in face_tnames:\n",
    "    class_indices[name] = face_targets_df.loc[face_targets_df['target_names']==name].index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "complete-training",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizziamo il primo dato per ogni classe\n",
    "\n",
    "fig1, axs1 = plt.subplots(len(face_tnames), 2, figsize=(8, len(face_tnames) * 3))\n",
    "\n",
    "for i in range(len(face_tnames)):\n",
    "    \n",
    "    name = face_tnames[i]\n",
    "    first_ind = class_indices[name][0]\n",
    "    \n",
    "    axs1[i, 0].bar(np.arange(face_data.shape[1]), face_data[first_ind, :])\n",
    "    axs1[i, 0].set_title('{} - vettore R^{}'.format(name, face_data.shape[1]))\n",
    "    \n",
    "    axs1[i, 1].imshow(face_images[first_ind], cmap=plt.cm.gray)\n",
    "    axs1[i, 1].set_title('{} - immagine/matrice R^{}x{}'.format(name, face_images.shape[1], face_images.shape[2]))\n",
    "\n",
    "plt.subplots_adjust(wspace=0.5, hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unsigned-relief",
   "metadata": {},
   "source": [
    "## PCA ed Eigenfaces\n",
    "\n",
    "La PCA è stata applicata (soprattutto in passato, prima dell'avvento del Deep Learning) a problemi di riconoscimento facciale. Tutt'oggi può essere utile per questi scopi o, per esempio, per la compressione di immagini.\n",
    "\n",
    "Proviamo quindi ad applicare la PCA ai vettori contenuti nella variabile \"face_data\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlikely-average",
   "metadata": {},
   "source": [
    "### Indagine Preliminare sulla Varianza Spiegata\n",
    "\n",
    "**ATTENZIONE:** in questo caso i vettori hanno come elementi i pixel delle immagini e assumono tutti valori tra 0 (nero) e 255 (bianco). Non si rende necessaria l'applicazione di uno StandardScaler (o simili).\n",
    "\n",
    "**ESERCIZIO:** Completare il codice della cella seguente per visualizzare l'andamento della varianza spiegata (percentuale) all'aumentare delle PC considerate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "understood-treaty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Inizializzazione oggetto PCA\n",
    "pca_global = ...\n",
    "# \"Fit\" dell'oggetto PCA\n",
    "...\n",
    "\n",
    "# Definizione di un array della varianza spiegata percentuale CUMULATIVA\n",
    "expld_variance_global = ...\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(expld_variance_global)\n",
    "plt.title('LFW')\n",
    "plt.xticks(ticks=np.arange(1, pca_global.n_features_ + 1, 100),\n",
    "           labels=[f'PC{i}' for i in range(1, pca_global.n_features_ + 1, 100)],\n",
    "           rotation=30)\n",
    "plt.xlabel('Principal components')\n",
    "plt.ylabel('Cumulative explained variance')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "failing-nitrogen",
   "metadata": {},
   "source": [
    "Guardando la curva della varianza spiegata, osserviamo che con un numero abbastanza ridotto di PC possiamo \"spiegare\" una buona percentuale della varianza totale.\n",
    "\n",
    "Prendiamo come esempio per l'esercizio una percentuale di varianza totale spiegata pari all'95%.\n",
    "\n",
    "**ESERCIZIO:** Completare il codice della cella seguente per implementare una PCA che selezioni un numero di PC corrispondenti al 95% di varianza totale spiegata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "regulation-significance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero PC: 142\n",
      "% Varianza Tot. Spiegata: 0.9502825736999512\n"
     ]
    }
   ],
   "source": [
    "pca_percentage = ...\n",
    "pca = ...\n",
    "...\n",
    "\n",
    "print('Numero PC: {}'.format(pca.n_components_))\n",
    "print('% Varianza Tot. Spiegata: {}'.format(pca.explained_variance_ratio_.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fleet-cache",
   "metadata": {},
   "source": [
    "### Eigenfaces\n",
    "\n",
    "Le cosiddette \"eigenfaces\" altro non sono che le PC (autovettori della matrice di covarianza del dataset) visualizzate come immagini invece che come vettori."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "intense-supervision",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vmin: -0.14872053265571594 (dark purple)\n",
      "vmax: 0.14872053265571594 (yellow)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Salviamo le PC \"risistemate\" come matrici/immagini in una lista apposita.\n",
    "\n",
    "_, height, width = face_images.shape\n",
    "eigenfaces = [pca.components_[i].reshape((height, width)) for i in range(pca.n_components_)]\n",
    "\n",
    "vmin = pca.components_.min()\n",
    "vmax = pca.components_.max()\n",
    "\n",
    "vmin = min([vmin, -vmax, 0.0])\n",
    "vmax = max([-vmin, vmax, 0.0])\n",
    "\n",
    "print('vmin: {} (dark purple)'.format(vmin))\n",
    "print('vmax: {} (yellow)'.format(vmax))\n",
    "\n",
    "# Numero di Eigenfaces da visualizzare (non tutte per allegerire l'esecuzione dei plot)\n",
    "n_pc_tosee = 5\n",
    "\n",
    "for i in range(n_pc_tosee): \n",
    "    fig, axs = plt.subplots(1, 3, figsize=(10, 4))\n",
    "    axs[0].bar(np.arange(pca.components_.shape[1]), pca.components_[i, :])\n",
    "    axs[0].set_title('PC{} - vettore R^{}'.format(i + 1, pca.components_.shape[1]))\n",
    "    \n",
    "    axs[1].imshow(eigenfaces[i], cmap=plt.cm.gnuplot2, vmin=vmin, vmax=vmax)\n",
    "    axs[1].set_title('PC{} - eigenface (vmin/vmax)'.format(i + 1, height, width))\n",
    "    \n",
    "    axs[2].imshow(eigenfaces[i], cmap=plt.cm.gray)\n",
    "    axs[2].set_title('PC{} - eigenface (normalized)'.format(i + 1, height, width))\n",
    "    \n",
    "    fig.suptitle('PC{} - {}% Var. Spiegata'.format(i + 1, np.around(100 * pca.explained_variance_ratio_[i], decimals=2)))\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polish-cholesterol",
   "metadata": {},
   "source": [
    "### Ricostruzione volti da Eigenfaces\n",
    "\n",
    "Vediamo come i volti presenti nel dataset vengono ricostruiti usando il numero di eigenfaces (cioè PC) che abbiamo selezionato (se le usassimo tutte e 1850, avremmo una ricostruzione esatta).\n",
    "\n",
    "**ESERCIZIO:** Completare il codice seguente per la comparare le immagini originali e la loro ricostruzione fatta usando il numero di PC scelto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-bunny",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selezione di \"n_randsamples\" volti random dal dataset\n",
    "\n",
    "n_randsamples = 25\n",
    "i_rand = np.random.choice(face_data.shape[0], n_randsamples, replace=False)\n",
    "\n",
    "# Definire una matrice di n_randsamples volti scelti secondo gli indici i_rand (una riga, un volto)\n",
    "rand_faces = ...\n",
    "\n",
    "# Definire la matrice \"built_randfaces\" rappresentante la matrice rand_faces ricostruita tramite le PC.\n",
    "# SUGGERIMENTO: usare i metodi \"transform\" e \"inverse_transform\" della PCA. \n",
    "built_randfaces = ...\n",
    "\n",
    "print('Sample Indices: {}'.format(i_rand))\n",
    "\n",
    "for i in range(n_randsamples):\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(8, 3))\n",
    "    ii = i_rand[i]\n",
    "    face_ii = face_images[ii]\n",
    "    builtface_ii = built_randfaces[i, :]\n",
    "    builtface_ii = builtface_ii.reshape((height, width))\n",
    "    \n",
    "    axs[0].imshow(face_ii, cmap=plt.cm.gray)\n",
    "    axs[0].set_title('Volto {} ({})'.format(ii, face_targets_df.loc[ii, 'target_names']))\n",
    "    \n",
    "    axs[1].imshow(builtface_ii, cmap=plt.cm.gray)\n",
    "    axs[1].set_title('Volto {} ricostruito'.format(ii))\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-drill",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
